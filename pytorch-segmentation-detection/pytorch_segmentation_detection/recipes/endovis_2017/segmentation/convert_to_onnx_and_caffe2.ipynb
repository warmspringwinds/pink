{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resnet18_8s(\n",
       "  (resnet18_8s): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=3)\n",
       "    (fc): Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(\"/home/daniil/repos/pytorch-segmentation-detection/\")\n",
    "sys.path.insert(0, '/home/daniil/repos/pytorch-segmentation-detection/vision/')\n",
    "sys.path.append(\"/home/daniil/repos/pytorch_fresh/pytorch/build/lib.linux-x86_64-2.7\")\n",
    "\n",
    "# Use second GPU -pytorch-segmentation-detection- change if you want to use a first one\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.onnx\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import pytorch_segmentation_detection.models.resnet_dilated as resnet_dilated\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "img_path = '/home/daniil/datasets/data/instrument_dataset_1/left_frames/frame000.png'\n",
    "\n",
    "valid_transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.CenterCrop((512, 512)),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                ])\n",
    "\n",
    "img_not_preprocessed = Image.open(img_path).convert('RGB')#.resize((512, 512))\n",
    "\n",
    "img = valid_transform(img_not_preprocessed)\n",
    "\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "img = img.cuda()\n",
    "\n",
    "fcn = resnet_dilated.Resnet18_8s(num_classes=2)\n",
    "fcn.load_state_dict(torch.load('/home/daniil/models/endovis_2017/resnet_18_8s_best.pth'))\n",
    "fcn.cuda()\n",
    "fcn.eval()\n",
    "\n",
    "# res = fcn(img)\n",
    "\n",
    "# _, tmp = res.squeeze(0).max(0)\n",
    "# segmentation = tmp.data.cpu().numpy().squeeze()\n",
    "\n",
    "# plt.imshow(img_not_preprocessed)\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(segmentation)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%actual_input_1 : Float(1, 3, 512, 512)\n",
      "      %learned_0 : Float(64, 3, 7, 7)\n",
      "      %learned_1 : Float(64)\n",
      "      %learned_2 : Float(64)\n",
      "      %learned_3 : Float(64)\n",
      "      %learned_4 : Float(64)\n",
      "      %learned_5 : Long()\n",
      "      %learned_6 : Float(64, 64, 3, 3)\n",
      "      %learned_7 : Float(64)\n",
      "      %learned_8 : Float(64)\n",
      "      %learned_9 : Float(64)\n",
      "      %learned_10 : Float(64)\n",
      "      %learned_11 : Long()\n",
      "      %learned_12 : Float(64, 64, 3, 3)\n",
      "      %learned_13 : Float(64)\n",
      "      %learned_14 : Float(64)\n",
      "      %learned_15 : Float(64)\n",
      "      %learned_16 : Float(64)\n",
      "      %learned_17 : Long()\n",
      "      %learned_18 : Float(64, 64, 3, 3)\n",
      "      %learned_19 : Float(64)\n",
      "      %learned_20 : Float(64)\n",
      "      %learned_21 : Float(64)\n",
      "      %learned_22 : Float(64)\n",
      "      %learned_23 : Long()\n",
      "      %learned_24 : Float(64, 64, 3, 3)\n",
      "      %learned_25 : Float(64)\n",
      "      %learned_26 : Float(64)\n",
      "      %learned_27 : Float(64)\n",
      "      %learned_28 : Float(64)\n",
      "      %learned_29 : Long()\n",
      "      %learned_30 : Float(128, 64, 3, 3)\n",
      "      %learned_31 : Float(128)\n",
      "      %learned_32 : Float(128)\n",
      "      %learned_33 : Float(128)\n",
      "      %learned_34 : Float(128)\n",
      "      %learned_35 : Long()\n",
      "      %learned_36 : Float(128, 128, 3, 3)\n",
      "      %learned_37 : Float(128)\n",
      "      %learned_38 : Float(128)\n",
      "      %learned_39 : Float(128)\n",
      "      %learned_40 : Float(128)\n",
      "      %learned_41 : Long()\n",
      "      %learned_42 : Float(128, 64, 1, 1)\n",
      "      %learned_43 : Float(128)\n",
      "      %learned_44 : Float(128)\n",
      "      %learned_45 : Float(128)\n",
      "      %learned_46 : Float(128)\n",
      "      %learned_47 : Long()\n",
      "      %learned_48 : Float(128, 128, 3, 3)\n",
      "      %learned_49 : Float(128)\n",
      "      %learned_50 : Float(128)\n",
      "      %learned_51 : Float(128)\n",
      "      %learned_52 : Float(128)\n",
      "      %learned_53 : Long()\n",
      "      %learned_54 : Float(128, 128, 3, 3)\n",
      "      %learned_55 : Float(128)\n",
      "      %learned_56 : Float(128)\n",
      "      %learned_57 : Float(128)\n",
      "      %learned_58 : Float(128)\n",
      "      %learned_59 : Long()\n",
      "      %learned_60 : Float(256, 128, 3, 3)\n",
      "      %learned_61 : Float(256)\n",
      "      %learned_62 : Float(256)\n",
      "      %learned_63 : Float(256)\n",
      "      %learned_64 : Float(256)\n",
      "      %learned_65 : Long()\n",
      "      %learned_66 : Float(256, 256, 3, 3)\n",
      "      %learned_67 : Float(256)\n",
      "      %learned_68 : Float(256)\n",
      "      %learned_69 : Float(256)\n",
      "      %learned_70 : Float(256)\n",
      "      %learned_71 : Long()\n",
      "      %learned_72 : Float(256, 128, 1, 1)\n",
      "      %learned_73 : Float(256)\n",
      "      %learned_74 : Float(256)\n",
      "      %learned_75 : Float(256)\n",
      "      %learned_76 : Float(256)\n",
      "      %learned_77 : Long()\n",
      "      %learned_78 : Float(256, 256, 3, 3)\n",
      "      %learned_79 : Float(256)\n",
      "      %learned_80 : Float(256)\n",
      "      %learned_81 : Float(256)\n",
      "      %learned_82 : Float(256)\n",
      "      %learned_83 : Long()\n",
      "      %learned_84 : Float(256, 256, 3, 3)\n",
      "      %learned_85 : Float(256)\n",
      "      %learned_86 : Float(256)\n",
      "      %learned_87 : Float(256)\n",
      "      %learned_88 : Float(256)\n",
      "      %learned_89 : Long()\n",
      "      %learned_90 : Float(512, 256, 3, 3)\n",
      "      %learned_91 : Float(512)\n",
      "      %learned_92 : Float(512)\n",
      "      %learned_93 : Float(512)\n",
      "      %learned_94 : Float(512)\n",
      "      %learned_95 : Long()\n",
      "      %learned_96 : Float(512, 512, 3, 3)\n",
      "      %learned_97 : Float(512)\n",
      "      %learned_98 : Float(512)\n",
      "      %learned_99 : Float(512)\n",
      "      %learned_100 : Float(512)\n",
      "      %learned_101 : Long()\n",
      "      %learned_102 : Float(512, 256, 1, 1)\n",
      "      %learned_103 : Float(512)\n",
      "      %learned_104 : Float(512)\n",
      "      %learned_105 : Float(512)\n",
      "      %learned_106 : Float(512)\n",
      "      %learned_107 : Long()\n",
      "      %learned_108 : Float(512, 512, 3, 3)\n",
      "      %learned_109 : Float(512)\n",
      "      %learned_110 : Float(512)\n",
      "      %learned_111 : Float(512)\n",
      "      %learned_112 : Float(512)\n",
      "      %learned_113 : Long()\n",
      "      %learned_114 : Float(512, 512, 3, 3)\n",
      "      %learned_115 : Float(512)\n",
      "      %learned_116 : Float(512)\n",
      "      %learned_117 : Float(512)\n",
      "      %learned_118 : Float(512)\n",
      "      %learned_119 : Long()\n",
      "      %learned_120 : Float(2, 512, 1, 1)\n",
      "      %learned_121 : Float(2)) {\n",
      "  %123 : Float(1, 64, 256, 256) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2]](%actual_input_1, %learned_0), scope: Resnet18_8s/ResNet[resnet18_8s]/Conv2d[conv1]\n",
      "  %124 : Float(1, 64, 256, 256) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%123, %learned_1, %learned_2, %learned_3, %learned_4), scope: Resnet18_8s/ResNet[resnet18_8s]/BatchNorm2d[bn1]\n",
      "  %125 : Float(1, 64, 256, 256) = onnx::Relu(%124), scope: Resnet18_8s/ResNet[resnet18_8s]/ReLU[relu]\n",
      "  %126 : Float(1, 64, 128, 128) = onnx::MaxPool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%125), scope: Resnet18_8s/ResNet[resnet18_8s]/MaxPool2d[maxpool]\n",
      "  %127 : Float(1, 64, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%126, %learned_6), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer1]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %128 : Float(1, 64, 128, 128) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%127, %learned_7, %learned_8, %learned_9, %learned_10), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer1]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %129 : Float(1, 64, 128, 128) = onnx::Relu(%128), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer1]/BasicBlock[0]/ReLU[relu]\n",
      "  %130 : Float(1, 64, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%129, %learned_12), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer1]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %131 : Float(1, 64, 128, 128) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%130, %learned_13, %learned_14, %learned_15, %learned_16), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer1]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %132 : Float(1, 64, 128, 128) = onnx::Add(%131, %126), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer1]/BasicBlock[0]\n",
      "  %133 : Float(1, 64, 128, 128) = onnx::Relu(%132), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer1]/BasicBlock[0]/ReLU[relu]\n",
      "  %134 : Float(1, 64, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%133, %learned_18), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer1]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %135 : Float(1, 64, 128, 128) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%134, %learned_19, %learned_20, %learned_21, %learned_22), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer1]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %136 : Float(1, 64, 128, 128) = onnx::Relu(%135), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer1]/BasicBlock[1]/ReLU[relu]\n",
      "  %137 : Float(1, 64, 128, 128) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%136, %learned_24), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer1]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %138 : Float(1, 64, 128, 128) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%137, %learned_25, %learned_26, %learned_27, %learned_28), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer1]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %139 : Float(1, 64, 128, 128) = onnx::Add(%138, %133), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer1]/BasicBlock[1]\n",
      "  %140 : Float(1, 64, 128, 128) = onnx::Relu(%139), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer1]/BasicBlock[1]/ReLU[relu]\n",
      "  %141 : Float(1, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%140, %learned_30), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %142 : Float(1, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%141, %learned_31, %learned_32, %learned_33, %learned_34), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %143 : Float(1, 128, 64, 64) = onnx::Relu(%142), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[0]/ReLU[relu]\n",
      "  %144 : Float(1, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%143, %learned_36), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %145 : Float(1, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%144, %learned_37, %learned_38, %learned_39, %learned_40), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %146 : Float(1, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%140, %learned_42), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %147 : Float(1, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%146, %learned_43, %learned_44, %learned_45, %learned_46), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %148 : Float(1, 128, 64, 64) = onnx::Add(%145, %147), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[0]\n",
      "  %149 : Float(1, 128, 64, 64) = onnx::Relu(%148), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[0]/ReLU[relu]\n",
      "  %150 : Float(1, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%149, %learned_48), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %151 : Float(1, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%150, %learned_49, %learned_50, %learned_51, %learned_52), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %152 : Float(1, 128, 64, 64) = onnx::Relu(%151), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[1]/ReLU[relu]\n",
      "  %153 : Float(1, 128, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%152, %learned_54), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %154 : Float(1, 128, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%153, %learned_55, %learned_56, %learned_57, %learned_58), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %155 : Float(1, 128, 64, 64) = onnx::Add(%154, %149), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[1]\n",
      "  %156 : Float(1, 128, 64, 64) = onnx::Relu(%155), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer2]/BasicBlock[1]/ReLU[relu]\n",
      "  %157 : Float(1, 256, 64, 64) = onnx::Conv[dilations=[2, 2], group=1, kernel_shape=[3, 3], pads=[2, 2, 2, 2], strides=[1, 1]](%156, %learned_60), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %158 : Float(1, 256, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%157, %learned_61, %learned_62, %learned_63, %learned_64), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %159 : Float(1, 256, 64, 64) = onnx::Relu(%158), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[0]/ReLU[relu]\n",
      "  %160 : Float(1, 256, 64, 64) = onnx::Conv[dilations=[2, 2], group=1, kernel_shape=[3, 3], pads=[2, 2, 2, 2], strides=[1, 1]](%159, %learned_66), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %161 : Float(1, 256, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%160, %learned_67, %learned_68, %learned_69, %learned_70), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %162 : Float(1, 256, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%156, %learned_72), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %163 : Float(1, 256, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%162, %learned_73, %learned_74, %learned_75, %learned_76), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %164 : Float(1, 256, 64, 64) = onnx::Add(%161, %163), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[0]\n",
      "  %165 : Float(1, 256, 64, 64) = onnx::Relu(%164), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[0]/ReLU[relu]\n",
      "  %166 : Float(1, 256, 64, 64) = onnx::Conv[dilations=[2, 2], group=1, kernel_shape=[3, 3], pads=[2, 2, 2, 2], strides=[1, 1]](%165, %learned_78), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %167 : Float(1, 256, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%166, %learned_79, %learned_80, %learned_81, %learned_82), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %168 : Float(1, 256, 64, 64) = onnx::Relu(%167), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[1]/ReLU[relu]\n",
      "  %169 : Float(1, 256, 64, 64) = onnx::Conv[dilations=[2, 2], group=1, kernel_shape=[3, 3], pads=[2, 2, 2, 2], strides=[1, 1]](%168, %learned_84), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %170 : Float(1, 256, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%169, %learned_85, %learned_86, %learned_87, %learned_88), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %171 : Float(1, 256, 64, 64) = onnx::Add(%170, %165), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[1]\n",
      "  %172 : Float(1, 256, 64, 64) = onnx::Relu(%171), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer3]/BasicBlock[1]/ReLU[relu]\n",
      "  %173 : Float(1, 512, 64, 64) = onnx::Conv[dilations=[4, 4], group=1, kernel_shape=[3, 3], pads=[4, 4, 4, 4], strides=[1, 1]](%172, %learned_90), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[0]/Conv2d[conv1]\n",
      "  %174 : Float(1, 512, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%173, %learned_91, %learned_92, %learned_93, %learned_94), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[0]/BatchNorm2d[bn1]\n",
      "  %175 : Float(1, 512, 64, 64) = onnx::Relu(%174), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[0]/ReLU[relu]\n",
      "  %176 : Float(1, 512, 64, 64) = onnx::Conv[dilations=[4, 4], group=1, kernel_shape=[3, 3], pads=[4, 4, 4, 4], strides=[1, 1]](%175, %learned_96), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[0]/Conv2d[conv2]\n",
      "  %177 : Float(1, 512, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%176, %learned_97, %learned_98, %learned_99, %learned_100), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[0]/BatchNorm2d[bn2]\n",
      "  %178 : Float(1, 512, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%172, %learned_102), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %179 : Float(1, 512, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%178, %learned_103, %learned_104, %learned_105, %learned_106), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %180 : Float(1, 512, 64, 64) = onnx::Add(%177, %179), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[0]\n",
      "  %181 : Float(1, 512, 64, 64) = onnx::Relu(%180), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[0]/ReLU[relu]\n",
      "  %182 : Float(1, 512, 64, 64) = onnx::Conv[dilations=[4, 4], group=1, kernel_shape=[3, 3], pads=[4, 4, 4, 4], strides=[1, 1]](%181, %learned_108), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[1]/Conv2d[conv1]\n",
      "  %183 : Float(1, 512, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%182, %learned_109, %learned_110, %learned_111, %learned_112), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[1]/BatchNorm2d[bn1]\n",
      "  %184 : Float(1, 512, 64, 64) = onnx::Relu(%183), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[1]/ReLU[relu]\n",
      "  %185 : Float(1, 512, 64, 64) = onnx::Conv[dilations=[4, 4], group=1, kernel_shape=[3, 3], pads=[4, 4, 4, 4], strides=[1, 1]](%184, %learned_114), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[1]/Conv2d[conv2]\n",
      "  %186 : Float(1, 512, 64, 64) = onnx::BatchNormalization[epsilon=1e-05, is_test=1, momentum=1](%185, %learned_115, %learned_116, %learned_117, %learned_118), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[1]/BatchNorm2d[bn2]\n",
      "  %187 : Float(1, 512, 64, 64) = onnx::Add(%186, %181), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[1]\n",
      "  %188 : Float(1, 512, 64, 64) = onnx::Relu(%187), scope: Resnet18_8s/ResNet[resnet18_8s]/Sequential[layer4]/BasicBlock[1]/ReLU[relu]\n",
      "  %189 : Float(1, 2, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%188, %learned_120, %learned_121), scope: Resnet18_8s/ResNet[resnet18_8s]/Conv2d[fc]\n",
      "  %output1 : Float(1, 2, 512, 512) = onnx::Upsample[height_scale=8, mode=bilinear, width_scale=8](%189), scope: Resnet18_8s\n",
      "  return (%output1);\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniil/repos/pytorch_fresh/pytorch/build/lib.linux-x86_64-2.7/torch/nn/functional.py:1761: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    }
   ],
   "source": [
    "# input and output names can be omitted -- the input will be named '0' in that case\n",
    "input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(122) ]\n",
    "output_names = [ \"output1\" ]\n",
    "\n",
    "torch.onnx.export(fcn, img, \"resnet_18_8s_binary_512.onnx\", verbose=True, input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_to_onnx.ipynb  resnet_18_8s_binary_512.onnx\r\n"
     ]
    }
   ],
   "source": [
    "# restart here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph torch-jit-export (\n",
      "  %actual_input_1[FLOAT, 1x3x512x512]\n",
      ") initializers (\n",
      "  %learned_0[FLOAT, 64x3x7x7]\n",
      "  %learned_1[FLOAT, 64]\n",
      "  %learned_2[FLOAT, 64]\n",
      "  %learned_3[FLOAT, 64]\n",
      "  %learned_4[FLOAT, 64]\n",
      "  %learned_5[INT64, scalar]\n",
      "  %learned_6[FLOAT, 64x64x3x3]\n",
      "  %learned_7[FLOAT, 64]\n",
      "  %learned_8[FLOAT, 64]\n",
      "  %learned_9[FLOAT, 64]\n",
      "  %learned_10[FLOAT, 64]\n",
      "  %learned_11[INT64, scalar]\n",
      "  %learned_12[FLOAT, 64x64x3x3]\n",
      "  %learned_13[FLOAT, 64]\n",
      "  %learned_14[FLOAT, 64]\n",
      "  %learned_15[FLOAT, 64]\n",
      "  %learned_16[FLOAT, 64]\n",
      "  %learned_17[INT64, scalar]\n",
      "  %learned_18[FLOAT, 64x64x3x3]\n",
      "  %learned_19[FLOAT, 64]\n",
      "  %learned_20[FLOAT, 64]\n",
      "  %learned_21[FLOAT, 64]\n",
      "  %learned_22[FLOAT, 64]\n",
      "  %learned_23[INT64, scalar]\n",
      "  %learned_24[FLOAT, 64x64x3x3]\n",
      "  %learned_25[FLOAT, 64]\n",
      "  %learned_26[FLOAT, 64]\n",
      "  %learned_27[FLOAT, 64]\n",
      "  %learned_28[FLOAT, 64]\n",
      "  %learned_29[INT64, scalar]\n",
      "  %learned_30[FLOAT, 128x64x3x3]\n",
      "  %learned_31[FLOAT, 128]\n",
      "  %learned_32[FLOAT, 128]\n",
      "  %learned_33[FLOAT, 128]\n",
      "  %learned_34[FLOAT, 128]\n",
      "  %learned_35[INT64, scalar]\n",
      "  %learned_36[FLOAT, 128x128x3x3]\n",
      "  %learned_37[FLOAT, 128]\n",
      "  %learned_38[FLOAT, 128]\n",
      "  %learned_39[FLOAT, 128]\n",
      "  %learned_40[FLOAT, 128]\n",
      "  %learned_41[INT64, scalar]\n",
      "  %learned_42[FLOAT, 128x64x1x1]\n",
      "  %learned_43[FLOAT, 128]\n",
      "  %learned_44[FLOAT, 128]\n",
      "  %learned_45[FLOAT, 128]\n",
      "  %learned_46[FLOAT, 128]\n",
      "  %learned_47[INT64, scalar]\n",
      "  %learned_48[FLOAT, 128x128x3x3]\n",
      "  %learned_49[FLOAT, 128]\n",
      "  %learned_50[FLOAT, 128]\n",
      "  %learned_51[FLOAT, 128]\n",
      "  %learned_52[FLOAT, 128]\n",
      "  %learned_53[INT64, scalar]\n",
      "  %learned_54[FLOAT, 128x128x3x3]\n",
      "  %learned_55[FLOAT, 128]\n",
      "  %learned_56[FLOAT, 128]\n",
      "  %learned_57[FLOAT, 128]\n",
      "  %learned_58[FLOAT, 128]\n",
      "  %learned_59[INT64, scalar]\n",
      "  %learned_60[FLOAT, 256x128x3x3]\n",
      "  %learned_61[FLOAT, 256]\n",
      "  %learned_62[FLOAT, 256]\n",
      "  %learned_63[FLOAT, 256]\n",
      "  %learned_64[FLOAT, 256]\n",
      "  %learned_65[INT64, scalar]\n",
      "  %learned_66[FLOAT, 256x256x3x3]\n",
      "  %learned_67[FLOAT, 256]\n",
      "  %learned_68[FLOAT, 256]\n",
      "  %learned_69[FLOAT, 256]\n",
      "  %learned_70[FLOAT, 256]\n",
      "  %learned_71[INT64, scalar]\n",
      "  %learned_72[FLOAT, 256x128x1x1]\n",
      "  %learned_73[FLOAT, 256]\n",
      "  %learned_74[FLOAT, 256]\n",
      "  %learned_75[FLOAT, 256]\n",
      "  %learned_76[FLOAT, 256]\n",
      "  %learned_77[INT64, scalar]\n",
      "  %learned_78[FLOAT, 256x256x3x3]\n",
      "  %learned_79[FLOAT, 256]\n",
      "  %learned_80[FLOAT, 256]\n",
      "  %learned_81[FLOAT, 256]\n",
      "  %learned_82[FLOAT, 256]\n",
      "  %learned_83[INT64, scalar]\n",
      "  %learned_84[FLOAT, 256x256x3x3]\n",
      "  %learned_85[FLOAT, 256]\n",
      "  %learned_86[FLOAT, 256]\n",
      "  %learned_87[FLOAT, 256]\n",
      "  %learned_88[FLOAT, 256]\n",
      "  %learned_89[INT64, scalar]\n",
      "  %learned_90[FLOAT, 512x256x3x3]\n",
      "  %learned_91[FLOAT, 512]\n",
      "  %learned_92[FLOAT, 512]\n",
      "  %learned_93[FLOAT, 512]\n",
      "  %learned_94[FLOAT, 512]\n",
      "  %learned_95[INT64, scalar]\n",
      "  %learned_96[FLOAT, 512x512x3x3]\n",
      "  %learned_97[FLOAT, 512]\n",
      "  %learned_98[FLOAT, 512]\n",
      "  %learned_99[FLOAT, 512]\n",
      "  %learned_100[FLOAT, 512]\n",
      "  %learned_101[INT64, scalar]\n",
      "  %learned_102[FLOAT, 512x256x1x1]\n",
      "  %learned_103[FLOAT, 512]\n",
      "  %learned_104[FLOAT, 512]\n",
      "  %learned_105[FLOAT, 512]\n",
      "  %learned_106[FLOAT, 512]\n",
      "  %learned_107[INT64, scalar]\n",
      "  %learned_108[FLOAT, 512x512x3x3]\n",
      "  %learned_109[FLOAT, 512]\n",
      "  %learned_110[FLOAT, 512]\n",
      "  %learned_111[FLOAT, 512]\n",
      "  %learned_112[FLOAT, 512]\n",
      "  %learned_113[INT64, scalar]\n",
      "  %learned_114[FLOAT, 512x512x3x3]\n",
      "  %learned_115[FLOAT, 512]\n",
      "  %learned_116[FLOAT, 512]\n",
      "  %learned_117[FLOAT, 512]\n",
      "  %learned_118[FLOAT, 512]\n",
      "  %learned_119[INT64, scalar]\n",
      "  %learned_120[FLOAT, 2x512x1x1]\n",
      "  %learned_121[FLOAT, 2]\n",
      ") {\n",
      "  %123 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [2, 2]](%actual_input_1, %learned_0)\n",
      "  %124 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%123, %learned_1, %learned_2, %learned_3, %learned_4)\n",
      "  %125 = Relu(%124)\n",
      "  %126 = MaxPool[kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%125)\n",
      "  %127 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%126, %learned_6)\n",
      "  %128 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%127, %learned_7, %learned_8, %learned_9, %learned_10)\n",
      "  %129 = Relu(%128)\n",
      "  %130 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%129, %learned_12)\n",
      "  %131 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%130, %learned_13, %learned_14, %learned_15, %learned_16)\n",
      "  %132 = Add(%131, %126)\n",
      "  %133 = Relu(%132)\n",
      "  %134 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%133, %learned_18)\n",
      "  %135 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%134, %learned_19, %learned_20, %learned_21, %learned_22)\n",
      "  %136 = Relu(%135)\n",
      "  %137 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%136, %learned_24)\n",
      "  %138 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%137, %learned_25, %learned_26, %learned_27, %learned_28)\n",
      "  %139 = Add(%138, %133)\n",
      "  %140 = Relu(%139)\n",
      "  %141 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%140, %learned_30)\n",
      "  %142 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%141, %learned_31, %learned_32, %learned_33, %learned_34)\n",
      "  %143 = Relu(%142)\n",
      "  %144 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%143, %learned_36)\n",
      "  %145 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%144, %learned_37, %learned_38, %learned_39, %learned_40)\n",
      "  %146 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%140, %learned_42)\n",
      "  %147 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%146, %learned_43, %learned_44, %learned_45, %learned_46)\n",
      "  %148 = Add(%145, %147)\n",
      "  %149 = Relu(%148)\n",
      "  %150 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%149, %learned_48)\n",
      "  %151 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%150, %learned_49, %learned_50, %learned_51, %learned_52)\n",
      "  %152 = Relu(%151)\n",
      "  %153 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%152, %learned_54)\n",
      "  %154 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%153, %learned_55, %learned_56, %learned_57, %learned_58)\n",
      "  %155 = Add(%154, %149)\n",
      "  %156 = Relu(%155)\n",
      "  %157 = Conv[dilations = [2, 2], group = 1, kernel_shape = [3, 3], pads = [2, 2, 2, 2], strides = [1, 1]](%156, %learned_60)\n",
      "  %158 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%157, %learned_61, %learned_62, %learned_63, %learned_64)\n",
      "  %159 = Relu(%158)\n",
      "  %160 = Conv[dilations = [2, 2], group = 1, kernel_shape = [3, 3], pads = [2, 2, 2, 2], strides = [1, 1]](%159, %learned_66)\n",
      "  %161 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%160, %learned_67, %learned_68, %learned_69, %learned_70)\n",
      "  %162 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%156, %learned_72)\n",
      "  %163 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%162, %learned_73, %learned_74, %learned_75, %learned_76)\n",
      "  %164 = Add(%161, %163)\n",
      "  %165 = Relu(%164)\n",
      "  %166 = Conv[dilations = [2, 2], group = 1, kernel_shape = [3, 3], pads = [2, 2, 2, 2], strides = [1, 1]](%165, %learned_78)\n",
      "  %167 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%166, %learned_79, %learned_80, %learned_81, %learned_82)\n",
      "  %168 = Relu(%167)\n",
      "  %169 = Conv[dilations = [2, 2], group = 1, kernel_shape = [3, 3], pads = [2, 2, 2, 2], strides = [1, 1]](%168, %learned_84)\n",
      "  %170 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%169, %learned_85, %learned_86, %learned_87, %learned_88)\n",
      "  %171 = Add(%170, %165)\n",
      "  %172 = Relu(%171)\n",
      "  %173 = Conv[dilations = [4, 4], group = 1, kernel_shape = [3, 3], pads = [4, 4, 4, 4], strides = [1, 1]](%172, %learned_90)\n",
      "  %174 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%173, %learned_91, %learned_92, %learned_93, %learned_94)\n",
      "  %175 = Relu(%174)\n",
      "  %176 = Conv[dilations = [4, 4], group = 1, kernel_shape = [3, 3], pads = [4, 4, 4, 4], strides = [1, 1]](%175, %learned_96)\n",
      "  %177 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%176, %learned_97, %learned_98, %learned_99, %learned_100)\n",
      "  %178 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%172, %learned_102)\n",
      "  %179 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%178, %learned_103, %learned_104, %learned_105, %learned_106)\n",
      "  %180 = Add(%177, %179)\n",
      "  %181 = Relu(%180)\n",
      "  %182 = Conv[dilations = [4, 4], group = 1, kernel_shape = [3, 3], pads = [4, 4, 4, 4], strides = [1, 1]](%181, %learned_108)\n",
      "  %183 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%182, %learned_109, %learned_110, %learned_111, %learned_112)\n",
      "  %184 = Relu(%183)\n",
      "  %185 = Conv[dilations = [4, 4], group = 1, kernel_shape = [3, 3], pads = [4, 4, 4, 4], strides = [1, 1]](%184, %learned_114)\n",
      "  %186 = BatchNormalization[epsilon = 9.99999974737875e-06, is_test = 1, momentum = 1](%185, %learned_115, %learned_116, %learned_117, %learned_118)\n",
      "  %187 = Add(%186, %181)\n",
      "  %188 = Relu(%187)\n",
      "  %189 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%188, %learned_120, %learned_121)\n",
      "  %output1 = Upsample[height_scale = 8, mode = u'bilinear', width_scale = 8](%189)\n",
      "  return %output1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# Run ```python setup.py build``` in the pytorch master repo\n",
    "sys.path.append(\"/home/daniil/repos/pytorch_fresh/pytorch/build/lib.linux-x86_64-2.7\")\n",
    "\n",
    "# Run ```python setup.py build``` in the third_party/onnx folder\n",
    "sys.path.append(\"/home/daniil/repos/pytorch_fresh/pytorch/third_party/onnx/build/lib.linux-x86_64-2.7/\")\n",
    "\n",
    "# Compile using cmake in the build folder\n",
    "sys.path.append(\"/home/daniil/repos/pytorch_fresh/pytorch/build/\")\n",
    "\n",
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"resnet_18_8s_binary_512.onnx\")\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(model.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to a caffe2 native representation\n",
    "# and saving to a protobuf file\n",
    "\n",
    "from caffe2.python.onnx.backend import Caffe2Backend\n",
    "\n",
    "init_net, predict_net = Caffe2Backend.onnx_graph_to_caffe2_net(model)\n",
    "\n",
    "# Let's also save the init_net and predict_net to a file that we will later use for running them on mobile\n",
    "with open('init_net.pb', \"wb\") as fopen:\n",
    "    fopen.write(init_net.SerializeToString())\n",
    "    \n",
    "with open('predict_net.pb', \"wb\") as fopen:\n",
    "    fopen.write(predict_net.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resort to a more low level interface -- without predictor but using our new fully converted weights\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(\"/home/daniil/repos/pytorch_fresh/pytorch/build/lib.linux-x86_64-2.7\")\n",
    "\n",
    "# Adding onnx compiled from sources\n",
    "sys.path.append(\"/home/daniil/repos/pytorch_fresh/pytorch/third_party/onnx/build/lib.linux-x86_64-2.7/\")\n",
    "\n",
    "# Adding caffe2 compiled from sources\n",
    "sys.path.append(\"/home/daniil/repos/pytorch_fresh/pytorch/build/\")\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os, time\n",
    "from caffe2.proto import caffe2_pb2\n",
    "from caffe2.python import workspace\n",
    "\n",
    "workspace.ResetWorkspace()\n",
    "\n",
    "device_opts = caffe2_pb2.DeviceOption()\n",
    "device_opts.device_type = caffe2_pb2.CUDA\n",
    "device_opts.cuda_gpu_id = 1\n",
    "\n",
    "init_def = caffe2_pb2.NetDef()\n",
    "with open('init_net.pb', 'rb') as f:\n",
    "    init_def.ParseFromString(f.read())\n",
    "    init_def.device_option.CopyFrom(device_opts)\n",
    "    workspace.RunNetOnce(init_def)\n",
    "\n",
    "workspace.FeedBlob('actual_input_1', np.random.rand(1, 3, 512, 512).astype(np.float32), device_opts)\n",
    "    \n",
    "net_def = caffe2_pb2.NetDef()\n",
    "with open('predict_net.pb', 'rb') as f:\n",
    "    net_def.ParseFromString(f.read())\n",
    "    net_def.device_option.CopyFrom(device_opts)\n",
    "    workspace.CreateNet(net_def, overwrite=True)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    \n",
    "    workspace.RunNet(net_def.name, 1)\n",
    "    end = time.time()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 29.2 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "# 29.3 ms\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
